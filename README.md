# ğŸŒ AI-Translate

**Multilingual media translation platform for AI hackathon**

Production-ready application that accepts media files, extracts text, translates to multiple languages, and generates localized audio output.

## ğŸ¯ Features

- **Multi-format Support**: Audio (MP3, WAV), Video (MP4, AVI, MKV), Images (JPG, PNG)
- **Smart Extraction**:
  - Speech-to-Text via Whisper
  - Optical Character Recognition (OCR) via PaddleOCR
- **Multilingual Translation**: Russian, Kazakh, English via NLLB-200
- **Audio Generation**: Text-to-Speech synthesis in target language
- **Async Processing**: Background job handling with real-time status
- **REST API**: FastAPI with comprehensive documentation
- **Web UI**: Streamlit for intuitive user interaction

## ğŸ—ï¸ Architecture

\`\`\`
ai-translate/
â”œâ”€â”€ app/                          # FastAPI backend
â”‚   â”œâ”€â”€ main.py                   # App entry point
â”‚   â”œâ”€â”€ config.py                 # Configuration
â”‚   â”œâ”€â”€ models/                   # Data models
â”‚   â”‚   â””â”€â”€ job.py               # Job schema
â”‚   â”œâ”€â”€ services/                 # ML services
â”‚   â”‚   â”œâ”€â”€ job_manager.py       # Job tracking
â”‚   â”‚   â”œâ”€â”€ speech_to_text.py    # Whisper integration
â”‚   â”‚   â”œâ”€â”€ image_to_text.py     # OCR integration
â”‚   â”‚   â”œâ”€â”€ translation.py        # NLLB integration
â”‚   â”‚   â””â”€â”€ text_to_speech.py    # TTS integration
â”‚   â”œâ”€â”€ routes/                   # API endpoints
â”‚   â”‚   â”œâ”€â”€ upload.py            # File upload
â”‚   â”‚   â”œâ”€â”€ results.py           # Result retrieval
â”‚   â”‚   â””â”€â”€ worker.py            # Background worker
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â””â”€â”€ file_utils.py        # File handling
â”œâ”€â”€ frontend/                     # Streamlit UI
â”‚   â””â”€â”€ app.py                   # Web interface
â”œâ”€â”€ scripts/                      # Test & run scripts
â”‚   â”œâ”€â”€ test_api.sh             # API testing
â”‚   â””â”€â”€ run.sh                  # Local/Docker launcher
â”œâ”€â”€ sample_files/                # Example media
â”œâ”€â”€ Dockerfile                   # Container image
â”œâ”€â”€ docker-compose.yml          # Multi-container setup
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment template
â””â”€â”€ README.md                  # This file
\`\`\`

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

\`\`\`bash
# Clone and setup
git clone <repo>
cd ai-translate

# Start with Docker Compose
docker-compose up --build

# Access:
# Backend:  http://localhost:8000
# Frontend: http://localhost:8501
# Docs:     http://localhost:8000/docs
\`\`\`

### Option 2: Local Installation

\`\`\`bash
# Requirements
- Python 3.11+
- FFmpeg (for audio/video processing)

# Setup
pip install -r requirements.txt

# Run
./scripts/run.sh local

# Or separately:
# Terminal 1: Backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Terminal 2: Frontend
streamlit run frontend/app.py --server.port 8501
\`\`\`

## ğŸ“¡ API Documentation

### Upload File
\`\`\`bash
POST /api/upload
Content-Type: multipart/form-data

Parameters:
- file: Binary file (audio/video/image)
- target_lang: "ru" | "en" | "kk"

Response:
{
  "job_id": "uuid",
  "status": "processing"
}
\`\`\`

### Get Results
\`\`\`bash
GET /api/result/{job_id}

Response:
{
  "job_id": "uuid",
  "status": "completed",
  "file_type": "audio|video|image",
  "source_text": "...",
  "translated_text": "...",
  "segments": [
    {"start": 0.0, "end": 5.0, "text": "..."}
  ],
  "image_bboxes": [
    {"x": 10, "y": 20, "width": 100, "height": 30, "text": "...", "confidence": 0.95}
  ],
  "audio_url": "/media/uuid.mp3"
}
\`\`\`

### List Jobs
\`\`\`bash
GET /api/jobs

Response:
{
  "jobs": [...],
  "total": 42
}
\`\`\`

## ğŸ§ª Testing

\`\`\`bash
# Run test suite
./scripts/test_api.sh

# Manual test with cURL
curl -X POST -F "file=@sample.mp3" -F "target_lang=en" http://localhost:8000/api/upload

# Interactive testing
curl http://localhost:8000/docs
\`\`\`

## ğŸ”§ Configuration

### Environment Variables

\`\`\`env
# API
API_BASE_URL=http://localhost:8000
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# File Paths
UPLOAD_DIR=/tmp/uploads
AUDIO_OUTPUT_DIR=/tmp/audio_output
MODELS_DIR=/tmp/models

# Models
WHISPER_MODEL=base              # Options: tiny, base, small, medium, large
NLLB_MODEL=facebook/nllb-200-distilled-600M

# Limits
MAX_FILE_SIZE=500              # MB
\`\`\`

### Model Downloads

Models auto-download on first use:
- **Whisper**: `~140MB` (base model)
- **NLLB**: `~1.2GB` (distilled-600M)
- **PaddleOCR**: `~200MB`
- **TTS**: `~300MB`

Set `MODELS_DIR` to persistent storage for faster subsequent runs.

## ğŸ“Š Processing Pipeline

### Audio/Video
\`\`\`
Upload â†’ Extract Audio â†’ Speech-to-Text â†’ Translate â†’ Text-to-Speech â†’ Generate MP3
\`\`\`

### Image
\`\`\`
Upload â†’ OCR Extract â†’ Translate â†’ Generate Speech â†’ Return Results
\`\`\`

## ğŸ¯ Supported Languages

| Code | Language | Status |
|------|----------|--------|
| en   | English  | âœ…     |
| ru   | Russian  | âœ…     |
| kk   | Kazakh   | âœ…     |

## ğŸ“ˆ Performance Notes

- **First run**: Slow (model downloads)
- **Subsequent runs**: Fast (cached models)
- **Large files**: May take 5-30 minutes
- **Recommended**: GPU machine (optional but faster)

## âš ï¸ Limitations

- Max file size: 500MB
- Supported formats: MP3, WAV, MP4, PNG, JPG
- Processing timeout: 1 hour per job
- Memory: ~4GB minimum recommended

## ğŸ› ï¸ Development

### Adding New Language

1. Update `SUPPORTED_LANGUAGES` in `app/config.py`
2. Add NLLB code to `NLLB_LANG_CODES`
3. Restart services

### Custom Model

Replace in `app/services/translation.py`:
\`\`\`python
NLLB_MODEL = "your/model/name"
\`\`\`

### Debugging

\`\`\`bash
# Enable debug logging
export LOG_LEVEL=DEBUG

# View container logs
docker-compose logs -f backend
docker-compose logs -f frontend

# API documentation
http://localhost:8000/docs
\`\`\`

## ğŸ“¦ Dependencies

**Core**:
- FastAPI: Web framework
- Streamlit: Frontend
- Uvicorn: ASGI server

**ML Models**:
- faster-whisper: Speech recognition
- PaddleOCR: Text recognition
- Transformers: Translation
- TTS: Audio synthesis

**Utilities**:
- FFmpeg: Media processing
- Pydantic: Data validation
- Requests: HTTP client

## ğŸ† Hackathon Ready

This project includes:
- âœ… Production-ready code structure
- âœ… Error handling & logging
- âœ… Docker deployment
- âœ… API documentation
- âœ… UI/UX for demos
- âœ… Extensible architecture
- âœ… Mock services for quick testing

## ğŸ“ License

MIT

## ğŸ‘¥ Contributing

1. Fork repository
2. Create feature branch
3. Submit pull request

## ğŸ¤ Support

For issues or questions:
1. Check API docs: `http://localhost:8000/docs`
2. Review logs: `docker-compose logs`
3. Test endpoint: `./scripts/test_api.sh`

---

**Built for AI Hackathon** ğŸš€
Made with â¤ï¸ by AI Engineering Team
